{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 10\n",
    "num_feature = 28 * 28\n",
    "num_train = 60000\n",
    "num_test = 10000\n",
    "num_machines = 20\n",
    "batch_size = 2\n",
    "\n",
    "num_iter = 5000\n",
    "exit_byzantine = True\n",
    "num_byz = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_total_grad(X, Y, theta, weight_lambda):\n",
    "\n",
    "    \"\"\"\n",
    "    :param X: shape(num_samples, features + 1)\n",
    "    :param Y: labels' one_hot array, shape(num_samples, features + 1)\n",
    "    :param theta: shape (num_classes, feature+1)\n",
    "    :param weight_lambda: scalar\n",
    "    :return: grad, shape(num_classes, feature+1)\n",
    "    \"\"\"\n",
    "    m = X.shape[0]\n",
    "    t = np.dot(theta, X.T)\n",
    "    t = t - np.max(t, axis=0)\n",
    "    pro = np.exp(t) / np.sum(np.exp(t), axis=0)\n",
    "    total_grad = -np.dot((Y.T - pro), X) / m + weight_lambda * theta\n",
    "    return total_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(X, Y, theta, weight_lambda):\n",
    "\n",
    "    m = X.shape[0]\n",
    "    t1 = np.dot(theta, X.T)\n",
    "    t1 = t1 - np.max(t1, axis=0)\n",
    "    t = np.exp(t1)\n",
    "    tmp = t / np.sum(t, axis=0)\n",
    "    loss = -np.sum(Y.T * np.log(tmp)) / m + weight_lambda * np.sum(theta ** 2) / 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_acc(test_x, test_y, theta):\n",
    "\n",
    "    pred = []\n",
    "    num = 0\n",
    "    m = test_x.shape[0]\n",
    "    for i in range(m):\n",
    "        t1 = np.dot(theta, test_x[i])\n",
    "        t1 = t1 - np.max(t1, axis=0)\n",
    "        pro = np.exp(t1) / np.sum(np.exp(t1), axis=0)\n",
    "        index = np.argmax(pro)\n",
    "        if index == test_y[i]:\n",
    "            num += 1\n",
    "    acc = float(num) / m\n",
    "    return acc, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_median(grad_li):\n",
    "\n",
    "    grad_array = np.array(grad_li)\n",
    "    grad_array = grad_array.reshape(num_machines, num_class * (num_feature + 1))\n",
    "    med = np.median(grad_array, axis=0)\n",
    "    med = med.reshape(num_class, num_feature + 1)\n",
    "    return med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "\n",
    "    def __init__(self, data_x, data_y, machine_id):\n",
    "\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.machine_id = machine_id\n",
    "\n",
    "    def calc_gradient(self, theta, weight_lambda, id):\n",
    "\n",
    "        m = self.data_x.shape[0]\n",
    "        id = random.randint(0, m - batch_size)\n",
    "        grad = cal_total_grad(self.data_x[id:(id + batch_size)], self.data_y[id:(id + batch_size)], theta,\n",
    "                              weight_lambda)\n",
    "        if (exit_byzantine == True and self.machine_id >= num_machines - num_byz):\n",
    "            grad = np.random.standard_normal((num_class, num_feature+1))*10000\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameter_server:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.theta_li = []\n",
    "        self.total_grad = []\n",
    "        self.acc_li = []\n",
    "        self.time_li = []\n",
    "\n",
    "        path = \"../data/mnist/\"\n",
    "        train_img = np.load(path + 'train_img.npy')  # shape(60000, 784)\n",
    "        train_lbl = np.load(path + 'train_lbl.npy')  # shape(60000,)\n",
    "        one_train_lbl = np.load(path + 'one_train_lbl.npy')  # shape(10, 60000)\n",
    "        test_img = np.load(path + 'test_img.npy')  # shape(10000, 784)\n",
    "        test_lbl = np.load(path + 'test_lbl.npy')  # shape(10000,)\n",
    "\n",
    "        bias_train = np.ones(num_train)\n",
    "        train_img_bias = np.column_stack((train_img, bias_train))\n",
    "\n",
    "        bias_test = np.ones(num_test)\n",
    "        test_img_bias = np.column_stack((test_img, bias_test))\n",
    "\n",
    "        self.test_img_bias = test_img_bias\n",
    "        self.test_lbl = test_lbl\n",
    "        self.train_img_bias = train_img_bias\n",
    "        self.one_train_lbl = one_train_lbl\n",
    "\n",
    "        samples_per_machine = num_train / num_machines\n",
    "\n",
    "        self.machines = []\n",
    "        for i in range(num_machines):\n",
    "            new_machine = Machine(train_img_bias[i * samples_per_machine:(i + 1) * samples_per_machine, :],\n",
    "                                  one_train_lbl[i * samples_per_machine:(i + 1) * samples_per_machine], i)\n",
    "            self.machines.append(new_machine)\n",
    "            \n",
    "    def broadcast(self, x, wei_lambda, id):\n",
    "\n",
    "        grad_li = []\n",
    "        for mac in self.machines:\n",
    "            grad_li.append(mac.calc_gradient(x, wei_lambda, id))\n",
    "        return grad_li\n",
    "\n",
    "    def train(self, init_theta, alpha, wei_lambda):\n",
    "\n",
    "        self.theta_li.append(init_theta)\n",
    "        sample_per_machine = num_train / num_machines\n",
    "\n",
    "        alpha = 0.0001\n",
    "        d = 0.00005\n",
    "        wei_lambda = 0.01\n",
    "        start = time.clock()\n",
    "        for i in range(num_iter):\n",
    "            alpha = d / np.sqrt(i + 1)\n",
    "            id = i % sample_per_machine\n",
    "            grad_li = self.broadcast(self.theta_li[-1], wei_lambda, id)\n",
    "            grad = my_median(grad_li)\n",
    "            new_x = self.theta_li[-1] - alpha * grad\n",
    "            self.theta_li.append(new_x)\n",
    "            # total = cal_total_grad(self.train_img_bias, self.one_train_lbl, new_x, wei_lambda)\n",
    "            # self.total_grad.append(np.linalg.norm(total))\n",
    "            if (i + 1) % 10 == 0:\n",
    "                iter_time = time.clock()\n",
    "                self.time_li.append(iter_time - start)\n",
    "                acc, _ = cal_acc(self.test_img_bias, self.test_lbl, new_x)\n",
    "                self.acc_li.append(acc)\n",
    "                print(\"step:\", i, \"acc:\", acc)\n",
    "        print(\"train end!\")\n",
    "\n",
    "    def plot(self):\n",
    "\n",
    "        s1 = 'gaussian/q8'\n",
    "        # np.save('./result/machine20/fault/same_attack4/q4/' + s1 + '/grad_norm_li.npy', self.total_grad)\n",
    "        # np.save('./result/machine20/fault/' + s1 + '/acc_li.npy', self.acc_li)\n",
    "\n",
    "        plt.plot(np.arange(len(self.acc_li)) * 10, self.acc_li)\n",
    "        plt.xlabel('iter')\n",
    "        plt.ylabel('accuracy')\n",
    "        # plt.savefig('./result/machine20/fault/' + s1 + '/acc.jpg')\n",
    "        plt.show()\n",
    "\n",
    "        # plt.semilogy(np.arange(num_iter), self.total_grad)\n",
    "        # plt.xlabel('iter')\n",
    "        # plt.ylabel('log||grad||')\n",
    "        # plt.savefig('./result/machine20/fault/same_attack4/q4/' + s1 + '/grad_norm.jpg')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/mnist/train_img.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6c763e665243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-6c763e665243>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0minit_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_feature\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00005\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6c763e665243>\u001b[0m in \u001b[0;36minit\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mserver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mserver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2a639ccfa24a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/mnist/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtrain_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_img.npy'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape(60000, 784)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train_lbl.npy'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape(60000,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mone_train_lbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'one_train_lbl.npy'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape(10, 60000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/mnist/train_img.npy'"
     ]
    }
   ],
   "source": [
    "def init():\n",
    "    server = Parameter_server()\n",
    "    return server\n",
    "\n",
    "\n",
    "def main():\n",
    "    server = init()\n",
    "    init_x = np.zeros((num_class, num_feature + 1))\n",
    "    alpha = 0.00005\n",
    "    wei_lam = 0.01\n",
    "    server.train(init_x, alpha, wei_lam)\n",
    "    server.plot()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root='data', train=True,download=False, transform=transform)\n",
    "test_data = datasets.MNIST(root='data',train=False,download=False,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
